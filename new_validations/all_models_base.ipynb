{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib as jb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from satellite_bathymetry.preprocessing import get_coord_from_pixel_pos, get_pixel_from_coord, ndwi, pixel_ndwi, pixel_log_ratio\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import tensorflow as tf\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>cspmb7</th>\n",
       "      <th>b2b4</th>\n",
       "      <th>b3b4</th>\n",
       "      <th>ndwi15</th>\n",
       "      <th>ndwi24</th>\n",
       "      <th>ndwi53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233</td>\n",
       "      <td>1130</td>\n",
       "      <td>3.195862</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.0483</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>27.041417</td>\n",
       "      <td>1.156761</td>\n",
       "      <td>1.092734</td>\n",
       "      <td>0.396622</td>\n",
       "      <td>0.294890</td>\n",
       "      <td>-0.143802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.273030</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>27.274666</td>\n",
       "      <td>1.155853</td>\n",
       "      <td>1.091779</td>\n",
       "      <td>0.395809</td>\n",
       "      <td>0.293431</td>\n",
       "      <td>-0.142149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>233</td>\n",
       "      <td>1132</td>\n",
       "      <td>3.299687</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>27.625527</td>\n",
       "      <td>1.155238</td>\n",
       "      <td>1.090825</td>\n",
       "      <td>0.395809</td>\n",
       "      <td>0.292487</td>\n",
       "      <td>-0.141439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>233</td>\n",
       "      <td>1133</td>\n",
       "      <td>3.268182</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>27.742739</td>\n",
       "      <td>1.155562</td>\n",
       "      <td>1.091031</td>\n",
       "      <td>0.396622</td>\n",
       "      <td>0.292915</td>\n",
       "      <td>-0.141674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>233</td>\n",
       "      <td>1134</td>\n",
       "      <td>3.278125</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.0517</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>27.742739</td>\n",
       "      <td>1.156505</td>\n",
       "      <td>1.091822</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.294290</td>\n",
       "      <td>-0.141909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x     y         z      b1      b2      b3      b4      b5      b6  \\\n",
       "0  233  1130  3.195862  0.1199  0.0887  0.0692  0.0483  0.0518  0.0328   \n",
       "1  233  1131  3.273030  0.1199  0.0886  0.0691  0.0484  0.0519  0.0335   \n",
       "2  233  1132  3.299687  0.1199  0.0886  0.0690  0.0485  0.0519  0.0336   \n",
       "3  233  1133  3.268182  0.1199  0.0885  0.0689  0.0484  0.0518  0.0336   \n",
       "4  233  1134  3.278125  0.1199  0.0884  0.0688  0.0482  0.0517  0.0336   \n",
       "\n",
       "       b7      b8     cspmb7      b2b4      b3b4    ndwi15    ndwi24    ndwi53  \n",
       "0  0.0315  0.0252  27.041417  1.156761  1.092734  0.396622  0.294890 -0.143802  \n",
       "1  0.0317  0.0254  27.274666  1.155853  1.091779  0.395809  0.293431 -0.142149  \n",
       "2  0.0320  0.0255  27.625527  1.155238  1.090825  0.395809  0.292487 -0.141439  \n",
       "3  0.0321  0.0256  27.742739  1.155562  1.091031  0.396622  0.292915 -0.141674  \n",
       "4  0.0321  0.0257  27.742739  1.156505  1.091822  0.397436  0.294290 -0.141909  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './generated/dataset_dataframe.pkl.z'\n",
    "df = jb.load(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8']\n",
    "#bands_cspm_features = df[['b1', 'b5', 'b6', 'cspmb7']]\n",
    "#bands_cspm_target = df.z\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df[columns], df.z, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Bands:\n",
      "R2 score: 0.9430189919392344\n",
      "MAE: 0.544732448277654\n",
      "MSE: 1.1495352442769153\n",
      "RMSE: 1.0721638141053424\n",
      "Bias: 0.03169882102740651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['generated/models/rf_model.pkl.z']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "p_rf = rf.predict(X_val)\n",
    "print('RF Bands:')\n",
    "print('R2 score:', r2_score(y_val, p_rf))\n",
    "print('MAE:', mean_absolute_error(y_val, p_rf))\n",
    "print('MSE:', mean_squared_error(y_val, p_rf))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_val, p_rf)))\n",
    "print('Bias:', p_rf.mean() - y_val.mean())\n",
    "jb.dump(rf,'generated/models/rf_model.pkl.z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Bands:\n",
      "R2 score: 0.9113324866743583\n",
      "Mean Absolute Error: 0.8632484611379012\n",
      "Mean Squared Error: 1.7887790170634044\n",
      "Root Mean Squared Error: 1.3374524354396324\n",
      "Bias: 0.04071945245236197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['generated/models/xgboost_model.pkl.z']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = XGBRegressor()\n",
    "xg.fit(X_train, y_train)\n",
    "p_xg = xg.predict(X_val)\n",
    "print('XGBoost Bands:')\n",
    "print('R2 score:', r2_score(y_val, p_xg))\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, p_xg))\n",
    "print('Mean Squared Error:', mean_squared_error(y_val, p_xg))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, p_xg)))\n",
    "print('Bias:', p_xg.mean() - y_val.mean())\n",
    "jb.dump(xg,'generated/models/xgboost_model.pkl.z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 - LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Bands:\n",
      "R2 score: 0.9483985691474017\n",
      "Mean Absolute Error: 0.5451373953237558\n",
      "Mean Squared Error: 1.041007617080458\n",
      "Root Mean Squared Error: 1.0202978080347218\n",
      "Bias: 0.028880756594481305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['generated/models/lgbm_model.pkl.z']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_lgbm = [0.06189835094365267, 9, 1, 0.8695551533271082, 0.6534274736020848, 976, 2, 1]\n",
    "lr = args_lgbm[0]\n",
    "max_depth = args_lgbm[1]\n",
    "min_child_samples = args_lgbm[2]\n",
    "subsample = args_lgbm[3]\n",
    "colsample_bytree = args_lgbm[4]\n",
    "n_estimators = args_lgbm[5]\n",
    "\n",
    "lgbm = LGBMRegressor(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth,\n",
    "                    min_child_samples=min_child_samples, subsample=subsample,\n",
    "                    colsample_bytree=colsample_bytree, bagging_freq=1, n_estimators=n_estimators,\n",
    "                    random_state=0, class_weight='balanced', n_jobs=6)\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "p_lgbm = lgbm.predict(X_val)\n",
    "\n",
    "print('LGBM Bands:')\n",
    "print('R2 score:', r2_score(y_val, p_lgbm))\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, p_lgbm))\n",
    "print('Mean Squared Error:', mean_squared_error(y_val, p_lgbm))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, p_lgbm)))\n",
    "print('Bias:', p_lgbm.mean() - y_val.mean())\n",
    "jb.dump(lgbm,'generated/models/lgbm_model.pkl.z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 - MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".............................................................................R2 score: 0.49922965731894153\n"
     ]
    }
   ],
   "source": [
    "def build_model(train_dataset):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(32, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "      ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "    return model\n",
    "\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        print('.', end='')\n",
    "\n",
    "EPOCHS = 1000\n",
    "model = build_model(X_train)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, validation_split=0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n",
    "p = model.predict(X_val).flatten()\n",
    "print('R2 score:', r2_score(y_val, p_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Bands:\n",
      "R2 score: 0.49922965731894153\n",
      "Mean Absolute Error: 2.3017458973957314\n",
      "Mean Squared Error: 10.102544300139767\n",
      "Root Mean Squared Error: 3.1784499838977753\n",
      "Bias: -0.05111900608094189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['generated/models/mlp_model.pkl.z']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPRegressor(random_state=42, max_iter=2000)\n",
    "mlp.fit(X_train, y_train)\n",
    "p_mlp = mlp.predict(X_val)\n",
    "\n",
    "print('MLP Bands:')\n",
    "print('R2 score:', r2_score(y_val, p_mlp))\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, p_mlp))\n",
    "print('Mean Squared Error:', mean_squared_error(y_val, p_mlp))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, p_mlp)))\n",
    "print('Bias:', p_mlp.mean() - y_val.mean())\n",
    "jb.dump(mlp,'generated/models/mlp_model.pkl.z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 - Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "R2 score: 0.47908435179078646\n",
      "Mean Absolute Error: 2.4851314794293233\n",
      "Mean Squared Error: 10.508955830919373\n",
      "Root Mean Squared Error: 3.2417519693707866\n",
      "Bias: 0.04283562506765204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['generated/models/lr_model.pkl.z']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "p_lr = lr.predict(X_val)\n",
    "\n",
    "print('Linear Regression')\n",
    "print('R2 score:', r2_score(y_val, p_lr))\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, p_lr))\n",
    "print('Mean Squared Error:', mean_squared_error(y_val, p_lr))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, p_lr)))\n",
    "print('Bias:', p_lr.mean() - y_val.mean())\n",
    "jb.dump(lr,'generated/models/lr_model.pkl.z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Polynomial Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_poly = LinearRegression()\n",
    "poly = PolynomialFeatures(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = poly.fit_transform(X_train)\n",
    "val_data = poly.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression Bands:\n",
      "R2 score: 0.6249267461302624\n",
      "Mean Absolute Error: 2.0092593661409035\n",
      "Mean Squared Error: 7.566730375304868\n",
      "Root Mean Squared Error: 2.7507690516117247\n",
      "Bias: 0.029257142366378552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['generated/models/poly.pkl.z']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_poly.fit(train_data, y_train)\n",
    "p_lr_poly = lr_poly.predict(val_data)\n",
    "\n",
    "print('Polynomial Regression Bands:')\n",
    "print('R2 score:', r2_score(y_val, p_lr_poly))\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, p_lr_poly))\n",
    "print('Mean Squared Error:', mean_squared_error(y_val, p_lr_poly))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, p_lr_poly)))\n",
    "print('Bias:', p_lr_poly.mean() - y_val.mean())\n",
    "jb.dump(lr_poly,'generated/models/poly_lr_model.pkl.z')\n",
    "jb.dump(poly,'generated/models/poly.pkl.z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster-based regression - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBR for 2 clusters:\n",
      "R2 score: 0.8707517219562176\n",
      "Mean Absolute Error: 1.183578349713524\n",
      "Mean Squared Error: 2.607455640570391\n",
      "Root Mean Squared Error: 1.614761790658421\n",
      "Bias: 0.0772045362526601\n",
      "CBR for 4 clusters:\n",
      "R2 score: 0.7420914989089337\n",
      "Mean Absolute Error: 1.8211755360314847\n",
      "Mean Squared Error: 5.2030478556407065\n",
      "Root Mean Squared Error: 2.281019038859761\n",
      "Bias: 0.7587057307944143\n",
      "CBR for 6 clusters:\n",
      "R2 score: 0.6921925995892648\n",
      "Mean Absolute Error: 1.87207670518734\n",
      "Mean Squared Error: 6.209708589993009\n",
      "Root Mean Squared Error: 2.491928688785658\n",
      "Bias: -0.057115438313007694\n",
      "CBR for 8 clusters:\n",
      "R2 score: 0.6580598952107686\n",
      "Mean Absolute Error: 2.051145997356112\n",
      "Mean Squared Error: 6.898302000339903\n",
      "Root Mean Squared Error: 2.626461878714386\n",
      "Bias: 0.016967358147188527\n"
     ]
    }
   ],
   "source": [
    "columns = ['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8']\n",
    "df_c = df.reset_index(drop=True)\n",
    "cluster_dict = dict()\n",
    "#for cluster_number in range(1,11,1):\n",
    "for cluster_number in range(2,10,2):\n",
    "    df_features = df_c[columns].copy()\n",
    "    kmeans = KMeans(n_clusters=cluster_number, random_state=0).fit(df_features)\n",
    "    df_features['cluster'] = kmeans.labels_\n",
    "\n",
    "    df_dist = pd.DataFrame(kmeans.transform(df_features.drop(['cluster'],axis=1)))\n",
    "    \n",
    "    drop_list = list()\n",
    "    for i in range(cluster_number):\n",
    "        drop_list.append(f'norm_dist_to_{i}')\n",
    "        \n",
    "    df_dist.columns = drop_list\n",
    "    for i in range(cluster_number):\n",
    "        df_dist[f'norm_dist_to_{i}'] = 1/df_dist[f'norm_dist_to_{i}']\n",
    "    df_dist['sum'] = df_dist.sum(axis=1)\n",
    "    for i in range(cluster_number):\n",
    "        df_dist[f'norm_dist_to_{i}'] = df_dist[f'norm_dist_to_{i}']/df_dist['sum']\n",
    "    df_dist.drop(['sum'],axis=1,inplace=True)\n",
    "\n",
    "    df_features = pd.concat([df_features,df_dist],axis=1)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df_features, df_c['z'], test_size=0.3, random_state=42)\n",
    "\n",
    "    \n",
    "    drop_list.append('cluster')\n",
    "\n",
    "    models = list()\n",
    "    for i in range(cluster_number):\n",
    "        X_train_model = X_train[X_train['cluster'] == i]\n",
    "        y_train_model = y_train[y_train.index.isin(X_train_model.index)]\n",
    "        X_train_model.drop(drop_list,axis=1)\n",
    "        obj = RandomForestRegressor()\n",
    "        obj.fit(X_train_model.drop(drop_list,axis=1), y_train_model)\n",
    "        models.append(obj)\n",
    "\n",
    "    predicts = list()\n",
    "    for i in range(cluster_number):\n",
    "        predict = models[i].predict(X_val.drop(drop_list,axis=1))*X_val[f'norm_dist_to_{i}']\n",
    "        predicts.append(predict)\n",
    "\n",
    "    df_predicts = pd.DataFrame(predicts).transpose()\n",
    "    df_predicts['predict'] = df_predicts.sum(axis=1)\n",
    "\n",
    "    result_dict = dict()\n",
    "    result_dict['r2'] = r2_score(y_val, df_predicts['predict'])\n",
    "    result_dict['mae'] = mean_absolute_error(y_val, df_predicts['predict'])\n",
    "    result_dict['mse'] = mean_squared_error(y_val, df_predicts['predict'])\n",
    "    result_dict['rmse'] = np.sqrt(mean_squared_error(y_val, df_predicts['predict']))\n",
    "    result_dict['bias'] = df_predicts['predict'].mean() - y_val.mean()\n",
    "\n",
    "    cluster_dict[str(cluster_number)] = result_dict\n",
    "    \n",
    "for key, val in cluster_dict.items():\n",
    "    print(f'CBR for {key} clusters:')\n",
    "    print('R2 score:', val['r2'])\n",
    "    print('Mean Absolute Error:', val['mae'])\n",
    "    print('Mean Squared Error:', val['mse'])\n",
    "    print('Root Mean Squared Error:', val['rmse'])\n",
    "    print('Bias:', val['bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster-based regression - Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBR for 2 clusters:\n",
      "R2 score: 0.41144564811306594\n",
      "Mean Absolute Error: 2.4207575647397044\n",
      "Mean Squared Error: 11.873499499080264\n",
      "Root Mean Squared Error: 3.4457944655884893\n",
      "Bias: -0.467501421740109\n",
      "CBR for 4 clusters:\n",
      "R2 score: 0.03719149859827531\n",
      "Mean Absolute Error: 3.031808631993668\n",
      "Mean Squared Error: 19.42370525755582\n",
      "Root Mean Squared Error: 4.407233288306375\n",
      "Bias: -2.299160163749069\n",
      "CBR for 6 clusters:\n",
      "R2 score: 0.2795254559163879\n",
      "Mean Absolute Error: 2.7439158370981738\n",
      "Mean Squared Error: 14.534858353949012\n",
      "Root Mean Squared Error: 3.8124609314652673\n",
      "Bias: 0.08066356915545025\n",
      "CBR for 8 clusters:\n",
      "R2 score: -0.3392787676197393\n",
      "Mean Absolute Error: 3.09171456766012\n",
      "Mean Squared Error: 27.018618969479125\n",
      "Root Mean Squared Error: 5.197943725116608\n",
      "Bias: -0.966848899595024\n"
     ]
    }
   ],
   "source": [
    "columns = ['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8']\n",
    "df_c = df.reset_index(drop=True)\n",
    "cluster_dict = dict()\n",
    "#for cluster_number in range(1,11,1):\n",
    "for cluster_number in range(2,10,2):\n",
    "    df_features = df_c[columns].copy()\n",
    "    kmeans = KMeans(n_clusters=cluster_number, random_state=0).fit(df_features)\n",
    "    df_features['cluster'] = kmeans.labels_\n",
    "\n",
    "    df_dist = pd.DataFrame(kmeans.transform(df_features.drop(['cluster'],axis=1)))\n",
    "    \n",
    "    drop_list = list()\n",
    "    for i in range(cluster_number):\n",
    "        drop_list.append(f'norm_dist_to_{i}')\n",
    "        \n",
    "    df_dist.columns = drop_list\n",
    "    for i in range(cluster_number):\n",
    "        df_dist[f'norm_dist_to_{i}'] = 1/df_dist[f'norm_dist_to_{i}']\n",
    "    df_dist['sum'] = df_dist.sum(axis=1)\n",
    "    for i in range(cluster_number):\n",
    "        df_dist[f'norm_dist_to_{i}'] = df_dist[f'norm_dist_to_{i}']/df_dist['sum']\n",
    "    df_dist.drop(['sum'],axis=1,inplace=True)\n",
    "\n",
    "    df_features = pd.concat([df_features,df_dist],axis=1)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df_features, df_c['z'], test_size=0.3, random_state=42)\n",
    "\n",
    "    \n",
    "    drop_list.append('cluster')\n",
    "\n",
    "    models = list()\n",
    "    for i in range(cluster_number):\n",
    "        X_train_model = X_train[X_train['cluster'] == i]\n",
    "        y_train_model = y_train[y_train.index.isin(X_train_model.index)]\n",
    "        X_train_model.drop(drop_list,axis=1)\n",
    "        \n",
    "        lr_poly = LinearRegression()\n",
    "        poly = PolynomialFeatures(degree=2)\n",
    "        \n",
    "        train_data_x = poly.fit_transform(X_train_model.drop(drop_list,axis=1))\n",
    "        \n",
    "        lr_poly.fit(train_data_x, y_train_model)\n",
    "        models.append([lr_poly,poly])\n",
    "\n",
    "    predicts = list()\n",
    "    for i in range(cluster_number):\n",
    "             \n",
    "        val_data = models[i][1].transform(X_val.drop(drop_list,axis=1))\n",
    "\n",
    "        predict = models[i][0].predict(val_data)*X_val[f'norm_dist_to_{i}']\n",
    "        predicts.append(predict)\n",
    "\n",
    "    df_predicts = pd.DataFrame(predicts).transpose()\n",
    "    df_predicts['predict'] = df_predicts.sum(axis=1)\n",
    "\n",
    "    result_dict = dict()\n",
    "    result_dict['r2'] = r2_score(y_val, df_predicts['predict'])\n",
    "    result_dict['mae'] = mean_absolute_error(y_val, df_predicts['predict'])\n",
    "    result_dict['mse'] = mean_squared_error(y_val, df_predicts['predict'])\n",
    "    result_dict['rmse'] = np.sqrt(mean_squared_error(y_val, df_predicts['predict']))\n",
    "    result_dict['bias'] = df_predicts['predict'].mean() - y_val.mean()\n",
    "\n",
    "    cluster_dict[str(cluster_number)] = result_dict\n",
    "    \n",
    "for key, val in cluster_dict.items():\n",
    "    print(f'CBR for {key} clusters:')\n",
    "    print('R2 score:', val['r2'])\n",
    "    print('Mean Absolute Error:', val['mae'])\n",
    "    print('Mean Squared Error:', val['mse'])\n",
    "    print('Root Mean Squared Error:', val['rmse'])\n",
    "    print('Bias:', val['bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster-based regression - Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBR for 2 clusters:\n",
      "R2 score: 0.5078980042667458\n",
      "Mean Absolute Error: 2.4033806761969068\n",
      "Mean Squared Error: 9.927669009841377\n",
      "Root Mean Squared Error: 3.1508203709258606\n",
      "Bias: -0.13637267198982972\n",
      "CBR for 4 clusters:\n",
      "R2 score: 0.5282716756970374\n",
      "Mean Absolute Error: 2.359662983300089\n",
      "Mean Squared Error: 9.516650423798428\n",
      "Root Mean Squared Error: 3.0849068744126504\n",
      "Bias: -0.18653825410760216\n",
      "CBR for 6 clusters:\n",
      "R2 score: 0.5015677255467221\n",
      "Mean Absolute Error: 2.3865535351806826\n",
      "Mean Squared Error: 10.055376095805936\n",
      "Root Mean Squared Error: 3.171021301695392\n",
      "Bias: -0.609355192049124\n",
      "CBR for 8 clusters:\n",
      "R2 score: 0.4901878398718702\n",
      "Mean Absolute Error: 2.4400133481308\n",
      "Mean Squared Error: 10.284953986831201\n",
      "Root Mean Squared Error: 3.207016368344758\n",
      "Bias: -0.4023503075346335\n"
     ]
    }
   ],
   "source": [
    "columns = ['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8']\n",
    "df_c = df.reset_index(drop=True)\n",
    "cluster_dict = dict()\n",
    "#for cluster_number in range(1,11,1):\n",
    "for cluster_number in range(2,10,2):\n",
    "    df_features = df_c[columns].copy()\n",
    "    kmeans = KMeans(n_clusters=cluster_number, random_state=0).fit(df_features)\n",
    "    df_features['cluster'] = kmeans.labels_\n",
    "\n",
    "    df_dist = pd.DataFrame(kmeans.transform(df_features.drop(['cluster'],axis=1)))\n",
    "    \n",
    "    drop_list = list()\n",
    "    for i in range(cluster_number):\n",
    "        drop_list.append(f'norm_dist_to_{i}')\n",
    "        \n",
    "    df_dist.columns = drop_list\n",
    "    for i in range(cluster_number):\n",
    "        df_dist[f'norm_dist_to_{i}'] = 1/df_dist[f'norm_dist_to_{i}']\n",
    "    df_dist['sum'] = df_dist.sum(axis=1)\n",
    "    for i in range(cluster_number):\n",
    "        df_dist[f'norm_dist_to_{i}'] = df_dist[f'norm_dist_to_{i}']/df_dist['sum']\n",
    "    df_dist.drop(['sum'],axis=1,inplace=True)\n",
    "\n",
    "    df_features = pd.concat([df_features,df_dist],axis=1)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df_features, df_c['z'], test_size=0.3, random_state=42)\n",
    "\n",
    "    \n",
    "    drop_list.append('cluster')\n",
    "\n",
    "    models = list()\n",
    "    for i in range(cluster_number):\n",
    "        X_train_model = X_train[X_train['cluster'] == i]\n",
    "        y_train_model = y_train[y_train.index.isin(X_train_model.index)]\n",
    "        X_train_model.drop(drop_list,axis=1)\n",
    "        \n",
    "        lr = LinearRegression()       \n",
    "        lr.fit(X_train_model.drop(drop_list,axis=1), y_train_model)\n",
    "        models.append(lr)\n",
    "\n",
    "    predicts = list()\n",
    "    for i in range(cluster_number):\n",
    "        \n",
    "        predict = models[i].predict(X_val.drop(drop_list,axis=1))*X_val[f'norm_dist_to_{i}']\n",
    "        predicts.append(predict)\n",
    "\n",
    "    df_predicts = pd.DataFrame(predicts).transpose()\n",
    "    df_predicts['predict'] = df_predicts.sum(axis=1)\n",
    "\n",
    "    result_dict = dict()\n",
    "    result_dict['r2'] = r2_score(y_val, df_predicts['predict'])\n",
    "    result_dict['mae'] = mean_absolute_error(y_val, df_predicts['predict'])\n",
    "    result_dict['mse'] = mean_squared_error(y_val, df_predicts['predict'])\n",
    "    result_dict['rmse'] = np.sqrt(mean_squared_error(y_val, df_predicts['predict']))\n",
    "    result_dict['bias'] = df_predicts['predict'].mean() - y_val.mean()\n",
    "\n",
    "    cluster_dict[str(cluster_number)] = result_dict\n",
    "    \n",
    "for key, val in cluster_dict.items():\n",
    "    print(f'CBR for {key} clusters:')\n",
    "    print('R2 score:', val['r2'])\n",
    "    print('Mean Absolute Error:', val['mae'])\n",
    "    print('Mean Squared Error:', val['mse'])\n",
    "    print('Root Mean Squared Error:', val['rmse'])\n",
    "    print('Bias:', val['bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
